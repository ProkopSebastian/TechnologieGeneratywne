{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d93347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 300 recipes\n",
      "Preparing texts for embedding...\n",
      "\n",
      "Sample embedding text:\n",
      "==================================================\n",
      "Recipe: Miso-Butter Roast Chicken With Acorn Squash Panzanella\n",
      "Ingredients: 1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher salt, divided, plus more, 2 small acorn squash (about 3 lb. total), 2 Tbsp. finely chopped sage, 1 Tbsp. finely chopped rosemary, 6 Tbsp. unsalted butter, melted, plus 3 Tbsp. room temperature, ¼ tsp. ground allspice, Pinch of crushed red pepper flakes, Freshly ground black pepper, ⅓ loaf good-quality sturdy white bread, torn into 1\" pieces (about 2½ cups), 2 medium apples (such...\n",
      "==================================================\n",
      "\n",
      "Creating embeddings for 300 recipes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 3/3 [00:08<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created embeddings for 300 recipes\n",
      "\n",
      "Saved files:\n",
      "- recipe_embeddings.pkl (full data with embeddings)\n",
      "- sample_recipes.json (sample recipes for inspection)\n",
      "\n",
      "Embedding stats:\n",
      "- Total recipes processed: 300\n",
      "- Embedding dimension: 1536\n",
      "- Average text length: 465 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../datasets/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\")\n",
    "\n",
    "# Take first 300 recipes for testing\n",
    "sample_df = df.head(300).copy()\n",
    "print(f\"Working with {len(sample_df)} recipes\")\n",
    "\n",
    "# Prepare texts for embedding\n",
    "def prepare_text_for_embedding(row):\n",
    "    \"\"\"Combine title and cleaned ingredients for embedding\"\"\"\n",
    "    title = row['Title']\n",
    "    ingredients = str(row['Cleaned_Ingredients'])  # Convert to string if it's not\n",
    "    \n",
    "    # Clean up the ingredients string (remove brackets, quotes)\n",
    "    ingredients_clean = ingredients.replace(\"['\", \"\").replace(\"']\", \"\").replace(\"', '\", \", \")\n",
    "    \n",
    "    # Combine title and ingredients\n",
    "    combined_text = f\"Recipe: {title}\\nIngredients: {ingredients_clean}\"\n",
    "    return combined_text\n",
    "\n",
    "# Prepare all texts\n",
    "print(\"Preparing texts for embedding...\")\n",
    "sample_df['embedding_text'] = sample_df.apply(prepare_text_for_embedding, axis=1)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample embedding text:\")\n",
    "print(\"=\"*50)\n",
    "print(sample_df['embedding_text'].iloc[0][:500] + \"...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function to get embeddings in batches\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    \"\"\"Get embeddings for a list of texts in batches\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Creating embeddings\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model\n",
    "            )\n",
    "            \n",
    "            batch_embeddings = [embedding.embedding for embedding in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            \n",
    "            # Small delay to avoid rate limits\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
    "            # Add empty embeddings for failed batch\n",
    "            embeddings.extend([None] * len(batch))\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Create embeddings\n",
    "print(f\"\\nCreating embeddings for {len(sample_df)} recipes...\")\n",
    "texts_to_embed = sample_df['embedding_text'].tolist()\n",
    "\n",
    "embeddings = get_embeddings_batch(texts_to_embed)\n",
    "\n",
    "# Add embeddings to dataframe\n",
    "sample_df['embedding'] = embeddings\n",
    "\n",
    "# Remove rows with failed embeddings\n",
    "sample_df = sample_df[sample_df['embedding'].notna()].copy()\n",
    "print(f\"Successfully created embeddings for {len(sample_df)} recipes\")\n",
    "\n",
    "# Save the processed data\n",
    "output_data = {\n",
    "    'recipes_df': sample_df.to_dict('records'),\n",
    "    'embeddings': [emb for emb in sample_df['embedding'].tolist()],\n",
    "    'embedding_model': 'text-embedding-3-small',\n",
    "    'created_at': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save as pickle for easy loading\n",
    "with open('recipe_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(output_data, f)\n",
    "\n",
    "# Also save as JSON (without embeddings for readability)\n",
    "sample_for_json = sample_df.drop(['embedding'], axis=1).head(10)\n",
    "with open('sample_recipes.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sample_for_json.to_dict('records'), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- recipe_embeddings.pkl (full data with embeddings)\")\n",
    "print(\"- sample_recipes.json (sample recipes for inspection)\")\n",
    "\n",
    "# Quick stats\n",
    "print(f\"\\nEmbedding stats:\")\n",
    "print(f\"- Total recipes processed: {len(sample_df)}\")\n",
    "print(f\"- Embedding dimension: {len(embeddings[0]) if embeddings and embeddings[0] else 'N/A'}\")\n",
    "print(f\"- Average text length: {sample_df['embedding_text'].str.len().mean():.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72caa58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING RECIPE SEARCH\n",
      "============================================================\n",
      "Searching for: 'chicken with vegetables'\n",
      "\n",
      "1. Golden Noodles With Chicken\n",
      "   Similarity: 0.506\n",
      "   Ingredients: ['Extra-virgin olive oil', '4 shallots, thinly sliced into rings', '1/4 cup unbleached all-purpose flour', '2 tablespoons extra virgin olive oil', '2 bone-in, skin-on chicken breasts', 'Kosher salt an...\n",
      "\n",
      "2. Tangy Vinegar Chicken With Barberries and Orange\n",
      "   Similarity: 0.492\n",
      "   Ingredients: ['3 lb. skin-on, bone-in chicken legs (thigh and drumstick) or a mix of thighs and drumsticks', 'Kosher salt', '2 Tbsp. vegetable or other neutral oil', '1 medium onion, finely chopped', '4 garlic clo...\n",
      "\n",
      "3. Chicken and Rice With Leeks and Salsa Verde\n",
      "   Similarity: 0.490\n",
      "   Ingredients: ['1½ lb. skinless, boneless chicken thighs (4–8 depending on size)', 'Kosher salt, freshly ground pepper', '3 Tbsp. unsalted butter, divided', '2 large or 3 medium leeks, white and pale green parts on...\n",
      "\n",
      "4. Spring Chicken Dinner Salad\n",
      "   Similarity: 0.472\n",
      "   Ingredients: ['2 large skinless, boneless chicken breasts (about 1¼ lb. total)', '3 Tbsp. Diamond Crystal or 3½ tsp. Morton kosher salt, plus more', '1 lemon, halved', '2 Tbsp. Dijon mustard', '6 Tbsp. extra-virgi...\n",
      "\n",
      "5. Chicken Pelau\n",
      "   Similarity: 0.472\n",
      "   Ingredients: ['1 cup dry or 1 (12-ounce) can pigeon peas, pinto beans, or black-eyed peas', '2 cups long-grain rice', '3 tablespoons canola oil', '3/4 cup sugar (white or brown)', '1 (3-pound) chicken, cut into 8 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test similarity function\n",
    "def find_similar_recipes(query, embeddings_data, top_k=5):\n",
    "    \"\"\"Find similar recipes using cosine similarity\"\"\"\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_response = client.embeddings.create(\n",
    "        input=[query],\n",
    "        model='text-embedding-3-small'\n",
    "    )\n",
    "    query_embedding = query_response.data[0].embedding\n",
    "    \n",
    "    # Calculate similarities\n",
    "    recipe_embeddings = np.array(embeddings_data['embeddings'])\n",
    "    similarities = cosine_similarity([query_embedding], recipe_embeddings)[0]\n",
    "    \n",
    "    # Get top results\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        recipe = embeddings_data['recipes_df'][idx]\n",
    "        results.append({\n",
    "            'title': recipe['Title'],\n",
    "            'similarity': similarities[idx],\n",
    "            'ingredients': recipe['Cleaned_Ingredients'][:200] + \"...\" if len(str(recipe['Cleaned_Ingredients'])) > 200 else recipe['Cleaned_Ingredients']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the search\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING RECIPE SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_query = \"chicken with vegetables\"\n",
    "print(f\"Searching for: '{test_query}'\")\n",
    "\n",
    "try:\n",
    "    similar_recipes = find_similar_recipes(test_query, output_data)\n",
    "    \n",
    "    for i, recipe in enumerate(similar_recipes, 1):\n",
    "        print(f\"\\n{i}. {recipe['title']}\")\n",
    "        print(f\"   Similarity: {recipe['similarity']:.3f}\")\n",
    "        print(f\"   Ingredients: {recipe['ingredients']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Search test failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
