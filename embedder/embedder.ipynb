{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d93347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1000 recipes\n",
      "Preparing texts for embedding...\n",
      "\n",
      "Sample embedding text:\n",
      "==================================================\n",
      "Recipe: Miso-Butter Roast Chicken With Acorn Squash Panzanella\n",
      "Ingredients: 1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher salt, divided, plus more, 2 small acorn squash (about 3 lb. total), 2 Tbsp. finely chopped sage, 1 Tbsp. finely chopped rosemary, 6 Tbsp. unsalted butter, melted, plus 3 Tbsp. room temperature, ¼ tsp. ground allspice, Pinch of crushed red pepper flakes, Freshly ground black pepper, ⅓ loaf good-quality sturdy white bread, torn into 1\" pieces (about 2½ cups), 2 medium apples (such...\n",
      "==================================================\n",
      "\n",
      "Creating embeddings for 1000 recipes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created embeddings for 1000 recipes\n",
      "\n",
      "Saved files:\n",
      "- recipe_embeddings.pkl (full data with embeddings)\n",
      "- sample_recipes.json (sample recipes for inspection)\n",
      "\n",
      "Embedding stats:\n",
      "- Total recipes processed: 1000\n",
      "- Embedding dimension: 1536\n",
      "- Average text length: 449 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../datasets/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\")\n",
    "\n",
    "# Take first 1000 recipes for testing\n",
    "sample_df = df.head(1000).copy()\n",
    "print(f\"Working with {len(sample_df)} recipes\")\n",
    "\n",
    "# Prepare texts for embedding\n",
    "def prepare_text_for_embedding(row):\n",
    "    \"\"\"Combine title and cleaned ingredients for embedding\"\"\"\n",
    "    title = row['Title']\n",
    "    ingredients = str(row['Cleaned_Ingredients'])  # Convert to string if it's not\n",
    "    \n",
    "    # Clean up the ingredients string (remove brackets, quotes)\n",
    "    ingredients_clean = ingredients.replace(\"['\", \"\").replace(\"']\", \"\").replace(\"', '\", \", \")\n",
    "    \n",
    "    # Combine title and ingredients\n",
    "    combined_text = f\"Recipe: {title}\\nIngredients: {ingredients_clean}\"\n",
    "    return combined_text\n",
    "\n",
    "# Prepare all texts\n",
    "print(\"Preparing texts for embedding...\")\n",
    "sample_df['embedding_text'] = sample_df.apply(prepare_text_for_embedding, axis=1)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample embedding text:\")\n",
    "print(\"=\"*50)\n",
    "print(sample_df['embedding_text'].iloc[0][:500] + \"...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function to get embeddings in batches\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    \"\"\"Get embeddings for a list of texts in batches\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Creating embeddings\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=batch,\n",
    "                model=model\n",
    "            )\n",
    "            \n",
    "            batch_embeddings = [embedding.embedding for embedding in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            \n",
    "            # Small delay to avoid rate limits\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
    "            # Add empty embeddings for failed batch\n",
    "            embeddings.extend([None] * len(batch))\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Create embeddings\n",
    "print(f\"\\nCreating embeddings for {len(sample_df)} recipes...\")\n",
    "texts_to_embed = sample_df['embedding_text'].tolist()\n",
    "\n",
    "embeddings = get_embeddings_batch(texts_to_embed)\n",
    "\n",
    "# Add embeddings to dataframe\n",
    "sample_df['embedding'] = embeddings\n",
    "\n",
    "# Remove rows with failed embeddings\n",
    "sample_df = sample_df[sample_df['embedding'].notna()].copy()\n",
    "print(f\"Successfully created embeddings for {len(sample_df)} recipes\")\n",
    "\n",
    "# Save the processed data\n",
    "output_data = {\n",
    "    'recipes_df': sample_df.to_dict('records'),\n",
    "    'embeddings': [emb for emb in sample_df['embedding'].tolist()],\n",
    "    'embedding_model': 'text-embedding-3-small',\n",
    "    'created_at': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save as pickle for easy loading\n",
    "with open('recipe_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(output_data, f)\n",
    "\n",
    "# Also save as JSON (without embeddings for readability)\n",
    "sample_for_json = sample_df.drop(['embedding'], axis=1).head(10)\n",
    "with open('sample_recipes.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sample_for_json.to_dict('records'), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- recipe_embeddings.pkl (full data with embeddings)\")\n",
    "print(\"- sample_recipes.json (sample recipes for inspection)\")\n",
    "\n",
    "# Quick stats\n",
    "print(f\"\\nEmbedding stats:\")\n",
    "print(f\"- Total recipes processed: {len(sample_df)}\")\n",
    "print(f\"- Embedding dimension: {len(embeddings[0]) if embeddings and embeddings[0] else 'N/A'}\")\n",
    "print(f\"- Average text length: {sample_df['embedding_text'].str.len().mean():.0f} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72caa58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING RECIPE SEARCH\n",
      "============================================================\n",
      "Searching for: 'chicken with vegetables'\n",
      "\n",
      "1. Soy-Glazed Chicken with Broccoli\n",
      "   Similarity: 0.512\n",
      "   Ingredients: ['3 Tbsp. honey', '3 Tbsp. soy sauce or tamari', '3 Tbsp. unseasoned rice vinegar', '1 tsp. finely grated ginger (from one 2\" piece)', '1 Tbsp. vegetable oil', '4 skinless, boneless chicken thighs', '...\n",
      "\n",
      "2. Golden Noodles With Chicken\n",
      "   Similarity: 0.506\n",
      "   Ingredients: ['Extra-virgin olive oil', '4 shallots, thinly sliced into rings', '1/4 cup unbleached all-purpose flour', '2 tablespoons extra virgin olive oil', '2 bone-in, skin-on chicken breasts', 'Kosher salt an...\n",
      "\n",
      "3. Chicken Brodo with Spring Vegetables and Fried Bread\n",
      "   Similarity: 0.499\n",
      "   Ingredients: ['4 lb. raw chicken bones', '3 spring onions or 4 scallions, chopped', '4 garlic cloves, crushed', '3 oz. thinly sliced prosciutto, chopped', '3/4 cup dried porcini mushrooms, rinsed', '1/3 cup extra-...\n",
      "\n",
      "4. Tandoori Chicken and Vegetable Sheet-Pan Supper\n",
      "   Similarity: 0.493\n",
      "   Ingredients: ['5 tablespoons organic canola oil', '4 cloves garlic, minced', '2 tablespoons grated fresh ginger', '1 tablespoon chili powder', '1 tablespoon garam masala', '2 teaspoons ground cumin', '2 teaspoons ...\n",
      "\n",
      "5. Tangy Vinegar Chicken With Barberries and Orange\n",
      "   Similarity: 0.492\n",
      "   Ingredients: ['3 lb. skin-on, bone-in chicken legs (thigh and drumstick) or a mix of thighs and drumsticks', 'Kosher salt', '2 Tbsp. vegetable or other neutral oil', '1 medium onion, finely chopped', '4 garlic clo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test similarity function\n",
    "def find_similar_recipes(query, embeddings_data, top_k=5):\n",
    "    \"\"\"Find similar recipes using cosine similarity\"\"\"\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_response = client.embeddings.create(\n",
    "        input=[query],\n",
    "        model='text-embedding-3-small'\n",
    "    )\n",
    "    query_embedding = query_response.data[0].embedding\n",
    "    \n",
    "    # Calculate similarities\n",
    "    recipe_embeddings = np.array(embeddings_data['embeddings'])\n",
    "    similarities = cosine_similarity([query_embedding], recipe_embeddings)[0]\n",
    "    \n",
    "    # Get top results\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        recipe = embeddings_data['recipes_df'][idx]\n",
    "        results.append({\n",
    "            'title': recipe['Title'],\n",
    "            'similarity': similarities[idx],\n",
    "            'ingredients': recipe['Cleaned_Ingredients'][:200] + \"...\" if len(str(recipe['Cleaned_Ingredients'])) > 200 else recipe['Cleaned_Ingredients']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the search\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING RECIPE SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_query = \"chicken with vegetables\"\n",
    "print(f\"Searching for: '{test_query}'\")\n",
    "\n",
    "try:\n",
    "    similar_recipes = find_similar_recipes(test_query, output_data)\n",
    "    \n",
    "    for i, recipe in enumerate(similar_recipes, 1):\n",
    "        print(f\"\\n{i}. {recipe['title']}\")\n",
    "        print(f\"   Similarity: {recipe['similarity']:.3f}\")\n",
    "        print(f\"   Ingredients: {recipe['ingredients']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Search test failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
