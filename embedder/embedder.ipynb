{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04fc1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "     -------------------------------------- 725.5/725.5 KB 6.6 MB/s eta 0:00:00\n",
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
      "     ------------------------------------- 327.7/327.7 KB 21.2 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 14.6 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 14.9 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB ? eta 0:00:00\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.3/65.3 KB ? eta 0:00:00\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "     ------------------------------------- 444.2/444.2 KB 13.6 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 73.5/73.5 KB 4.2 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "     -------------------------------------- 100.9/100.9 KB 5.7 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "     ------------------------------------- 207.5/207.5 KB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from openai) (4.14.0)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting protobuf>=3.20.0\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "     ------------------------------------- 435.3/435.3 KB 13.7 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.41.0\n",
      "  Downloading grpcio-1.72.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 15.9 MB/s eta 0:00:00\n",
      "Collecting portalocker<3.0.0,>=2.7.0\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting urllib3<3,>=1.26.14\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "     ---------------------------------------- 128.7/128.7 KB ? eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     ------------------------------------- 347.8/347.8 KB 10.9 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ------------------------------------- 509.2/509.2 KB 16.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 KB 3.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.8/78.8 KB ? eta 0:00:00\n",
      "Collecting certifi\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "     ---------------------------------------- 159.6/159.6 KB ? eta 0:00:00\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting h2<5,>=3\n",
      "  Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 61.0/61.0 KB ? eta 0:00:00\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (310)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kamil\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting hpack<5,>=4.1\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Collecting hyperframe<7,>=6.1\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, typing-inspection, tqdm, sniffio, python-dotenv, pydantic-core, protobuf, portalocker, numpy, more-itertools, jiter, idna, hyperframe, hpack, h11, grpcio, distro, certifi, annotated-types, pydantic, pandas, httpcore, h2, anyio, httpx, openai, qdrant-client\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 distro-1.9.0 grpcio-1.72.1 h11-0.16.0 h2-4.2.0 hpack-4.1.0 httpcore-1.0.9 httpx-0.28.1 hyperframe-6.1.0 idna-3.10 jiter-0.10.0 more-itertools-10.7.0 numpy-2.2.6 openai-1.84.0 pandas-2.3.0 portalocker-2.10.1 protobuf-6.31.1 pydantic-2.11.5 pydantic-core-2.33.2 python-dotenv-1.1.0 pytz-2025.2 qdrant-client-1.14.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# install required dependencies\n",
    "%pip install openai qdrant-client pandas numpy tqdm python-dotenv more-itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ff3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d93347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1000 recipes\n",
      "Preparing texts for embedding...\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n",
      "C:\\Users\\kamil\\AppData\\Local\\Temp\\ipykernel_25700\\2237240445.py:54: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully created 1000 embeddings\n",
      "Creating Qdrant collection...\n",
      "Uploading to Qdrant...\n",
      "✅ Upload complete.\n",
      "Total points uploaded: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Connect to Qdrant\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)  # adjust if running in Docker or remote\n",
    "\n",
    "COLLECTION_NAME = \"recipes\"\n",
    "VECTOR_SIZE = 1536  # for text-embedding-3-small\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../datasets/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\")\n",
    "\n",
    "# Take first 1000 recipes for testing\n",
    "sample_df = df.head(1000).copy()\n",
    "print(f\"Working with {len(sample_df)} recipes\")\n",
    "\n",
    "# Prepare texts for embedding\n",
    "def prepare_text_for_embedding(row):\n",
    "    title = row['Title']\n",
    "    ingredients = str(row['Cleaned_Ingredients'])\n",
    "    ingredients_clean = ingredients.replace(\"['\", \"\").replace(\"']\", \"\").replace(\"', '\", \", \")\n",
    "    return f\"Recipe: {title}\\nIngredients: {ingredients_clean}\"\n",
    "\n",
    "print(\"Preparing texts for embedding...\")\n",
    "sample_df['embedding_text'] = sample_df.apply(prepare_text_for_embedding, axis=1)\n",
    "\n",
    "# Batch embedding\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Creating embeddings\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            response = client.embeddings.create(input=batch, model=model)\n",
    "            batch_embeddings = [embedding.embedding for embedding in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on batch {i//batch_size+1}: {e}\")\n",
    "            embeddings.extend([None] * len(batch))\n",
    "    return embeddings\n",
    "\n",
    "print(\"Creating embeddings...\")\n",
    "texts = sample_df['embedding_text'].tolist()\n",
    "embeddings = get_embeddings_batch(texts)\n",
    "sample_df['embedding'] = embeddings\n",
    "\n",
    "# Remove failed ones\n",
    "sample_df = sample_df[sample_df['embedding'].notna()].copy()\n",
    "print(f\"✅ Successfully created {len(sample_df)} embeddings\")\n",
    "\n",
    "# Recreate collection if needed\n",
    "print(\"Creating Qdrant collection...\")\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Upload to Qdrant in batches\n",
    "print(\"Uploading to Qdrant...\")\n",
    "\n",
    "points = []\n",
    "for _, row in sample_df.iterrows():\n",
    "    payload = {\n",
    "        \"page_content\": row['embedding_text'],\n",
    "        \"title\": row.get(\"Title\", \"\"),\n",
    "        \"ingredients\": row.get(\"Cleaned_Ingredients\", \"\"),\n",
    "        \"instructions\": row.get(\"Instructions\", \"\"),\n",
    "        \"image_name\": row.get(\"Image_Name\", \"\"),\n",
    "        \"id\": row.get(\"Unnamed: 0\", -1)\n",
    "    }\n",
    "    points.append(PointStruct(id=str(uuid4()), vector=row['embedding'], payload=payload))\n",
    "\n",
    "# Batch upload\n",
    "from more_itertools import chunked\n",
    "for batch in chunked(points, 100):\n",
    "    qdrant.upsert(collection_name=COLLECTION_NAME, points=batch)\n",
    "\n",
    "print(\"✅ Upload complete.\")\n",
    "print(f\"Total points uploaded: {len(points)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caa58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING QDRANT RECIPE SEARCH\n",
      "============================================================\n",
      "Searching for: 'chicken with vegetables'\n",
      "\n",
      "1. Soy-Glazed Chicken with Broccoli\n",
      "   Similarity: 0.512\n",
      "   Ingredients: ['3 Tbsp. honey', '3 Tbsp. soy sauce or tamari', '3 Tbsp. unseasoned rice vinegar', '1 tsp. finely grated ginger (from one 2\" piece)', '1 Tbsp. vegetable oil', '4 skinless, boneless chicken thighs', '...\n",
      "\n",
      "2. Golden Noodles With Chicken\n",
      "   Similarity: 0.506\n",
      "   Ingredients: ['Extra-virgin olive oil', '4 shallots, thinly sliced into rings', '1/4 cup unbleached all-purpose flour', '2 tablespoons extra virgin olive oil', '2 bone-in, skin-on chicken breasts', 'Kosher salt an...\n",
      "\n",
      "3. Chicken Brodo with Spring Vegetables and Fried Bread\n",
      "   Similarity: 0.499\n",
      "   Ingredients: ['4 lb. raw chicken bones', '3 spring onions or 4 scallions, chopped', '4 garlic cloves, crushed', '3 oz. thinly sliced prosciutto, chopped', '3/4 cup dried porcini mushrooms, rinsed', '1/3 cup extra-...\n",
      "\n",
      "4. Tandoori Chicken and Vegetable Sheet-Pan Supper\n",
      "   Similarity: 0.493\n",
      "   Ingredients: ['5 tablespoons organic canola oil', '4 cloves garlic, minced', '2 tablespoons grated fresh ginger', '1 tablespoon chili powder', '1 tablespoon garam masala', '2 teaspoons ground cumin', '2 teaspoons ...\n",
      "\n",
      "5. Tangy Vinegar Chicken With Barberries and Orange\n",
      "   Similarity: 0.492\n",
      "   Ingredients: ['3 lb. skin-on, bone-in chicken legs (thigh and drumstick) or a mix of thighs and drumsticks', 'Kosher salt', '2 Tbsp. vegetable or other neutral oil', '1 medium onion, finely chopped', '4 garlic clo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamil\\AppData\\Local\\Temp\\ipykernel_25700\\1099346726.py:24: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = qdrant.search(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Filter, SearchRequest\n",
    "\n",
    "# Connect to Qdrant\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)  # adjust as needed\n",
    "\n",
    "# Test similarity function using vector DB\n",
    "def find_similar_recipes_from_qdrant(query, top_k=5, collection_name=\"recipes\"):\n",
    "    \"\"\"Find similar recipes using Qdrant vector search\"\"\"\n",
    "\n",
    "    # Step 1: Embed the query using OpenAI\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=[query],\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        query_vector = response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to embed query: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Step 2: Search in Qdrant\n",
    "    try:\n",
    "        hits = qdrant.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_k\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        for hit in hits:\n",
    "            payload = hit.payload\n",
    "            results.append({\n",
    "                \"title\": payload.get(\"title\", \"Unknown\"),\n",
    "                \"similarity\": hit.score,\n",
    "                \"ingredients\": payload.get(\"ingredients\", \"\")[:200] + \"...\" if len(payload.get(\"ingredients\", \"\")) > 200 else payload.get(\"ingredients\", \"\")\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Qdrant search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test the search\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING QDRANT RECIPE SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_query = \"chicken with vegetables\"\n",
    "print(f\"Searching for: '{test_query}'\")\n",
    "\n",
    "try:\n",
    "    similar_recipes = find_similar_recipes_from_qdrant(test_query)\n",
    "\n",
    "    for i, recipe in enumerate(similar_recipes, 1):\n",
    "        print(f\"\\n{i}. {recipe['title']}\")\n",
    "        print(f\"   Similarity: {recipe['similarity']:.3f}\")\n",
    "        print(f\"   Ingredients: {recipe['ingredients']}\")\n",
    "        print(f\"   image: \")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Search test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca5082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782403b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
